# Purpose of file
Yes-- this file has been included on purpose to illustrate vibe coding from a guy who doesn't have a lot of free time to code from scratch. Here, I'm using ChatGPT to bootstrap project creation.

# Body
Note, we will implement as much of this project in Go as makes sense. Python for those bits and pieces which require it-- e.g. MCP integration and/or LangGraph integration.
â¸»

ðŸ”§ Updated Tech Stack Plan

Component	Language	Notes
CLI & file parsing	Go	Fast, clean, and easily deployable
Markdown section splitter	Go	Regex or parser library
LLM interaction (OpenAI/Groq)	Go (via HTTP) or Python (LangGraph module)	Go if keeping simple; Python if using LangGraph
LangGraph workflow (optional)	Python	Only if you want multi-step node orchestration
Report rendering	Go	Colorized terminal + optional JSON
Unit tests	Go	Use go test with fixtures
LLM prompt templates	Text or Go constants	Reuse across components


â¸»

ðŸ§± Project Scaffold

prfaq-reviewer/
â”œâ”€â”€ cmd/
â”‚   â””â”€â”€ prfaq-reviewer/          # CLI entrypoint (Go)
â”œâ”€â”€ internal/
â”‚   â”œâ”€â”€ parser/                  # Markdown parsing & section tagging (Go)
â”‚   â”œâ”€â”€ analyzer/                # Flags/suggestions logic (Go)
â”‚   â””â”€â”€ llm/
â”‚       â”œâ”€â”€ client.go            # Calls out to LLM service (Go)
â”‚       â””â”€â”€ langgraph_bridge.py # (Optional) Python fallback for LangGraph
â”œâ”€â”€ prompts/
â”‚   â””â”€â”€ review_prompt.txt       # System/user prompt templates
â”œâ”€â”€ testdata/
â”‚   â””â”€â”€ example_prfaq.md
â”œâ”€â”€ go.mod / go.sum
â”œâ”€â”€ README.md
â””â”€â”€ Makefile


â¸»

ðŸªœ Development Phases (Go-First)

â¸»

âœ… Phase 1: All-in-Go MVP
	â€¢	CLI: prfaq-reviewer input.md
	â€¢	Parse Markdown into:
	â€¢	Press Release
	â€¢	FAQ
	â€¢	Success Metrics
	â€¢	Send entire content as one prompt to OpenAI API (via Go HTTP client)
	â€¢	Output:
	â€¢	Summary
	â€¢	Flags
	â€¢	Suggestions
	â€¢	Readiness Score

â¸»

ðŸ§ª Phase 2: Modular LLM Node Workflow (Optional via LangGraph)

If you find that a single-shot prompt becomes messy, move this logic into Python/LangGraph:
	â€¢	Go sends markdown chunks to Python as JSON
	â€¢	Python LangGraph routes each section to different LLM nodes
	â€¢	Returns structured output to Go

Simple interface contract:

POST /analyze
{
  "press_release": "...",
  "faq": "...",
  "metrics": "..."
}
â†’
{
  "summary": "...",
  "flags": [...],
  "suggestions": [...],
  "score": 7.5
}

You can call this as a subprocess from Go (or run a local HTTP server in Python).
