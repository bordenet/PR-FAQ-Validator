# Purpose of file
Yes-- this file has been included on purpose to illustrate vibe coding from a guy who doesn't have a lot of free time to code from scratch. Here, I'm using ChatGPT to bootstrap project creation.
# Body
üßæ Requirements Doc: PR-FAQ / Spec Reviewer AI

‚∏ª

üìå One-Liner

Build a developer-first tool that uses an LLM to analyze product documents (PR-FAQs, specs, RFCs) for clarity, completeness, and rigor‚Äîsuggesting improvements and flagging ambiguous or vague content.

‚∏ª

üéØ Goals
	‚Ä¢	Help PMs and engineers improve written specs via LLM-generated feedback
	‚Ä¢	Encourage a culture of clarity, ownership, and measurable outcomes
	‚Ä¢	Provide a structured critique rather than a fuzzy rewrite
	‚Ä¢	Fit into a CLI-based SDLC toolchain; possible GitHub Action or VS Code extension later

‚∏ª

üíº Users
	‚Ä¢	Primary: Staff+ PMs, Staff+ Engineers writing PR-FAQs/specs
	‚Ä¢	Secondary: VPs/Directors reviewing early planning docs

‚∏ª

üß† Core Use Case

User runs:

prfaq-reviewer input.md

And gets back:

== Summary ==

This PR-FAQ presents a compelling customer problem, but lacks measurable success criteria and assumes internal technical knowledge.

== Flags ==

[Line 12] "Significant performance improvement" ‚Üí vague term  
[Line 47] "Some teams may..." ‚Üí who exactly?  

== Suggestions ==

- Clarify the FAQ response to "What does success look like?"
- Add real metrics: latency? conversion? revenue?

== Overall Readiness Score: 7.5 / 10 ==


‚∏ª

üß± Key Components

‚∏ª

‚úÖ Input
	‚Ä¢	One .md file (PR-FAQ or spec)
	‚Ä¢	Optionally: section heuristics to help LangGraph route analysis (see below)

‚∏ª

‚úÖ Output
	‚Ä¢	Structured report, including:
	‚Ä¢	Summary
	‚Ä¢	Flags (vague, inconsistent, missing ownership, passive voice, weasel words, unclear success metrics)
	‚Ä¢	Suggestions (what to add/clarify)
	‚Ä¢	Optional score (for CI)

‚∏ª

‚úÖ Functional Requirements

Feature	Description
Markdown parsing	Parse sections: Press Release, FAQs, Metrics
Content analysis	LLM checks for vague terms, missing owners, unclear outcomes
Heuristic tagging	Use regex/NLP to pre-label weasel words or passive constructions
LLM-based critique	Summarize issues with clarity, conciseness, impact
CLI interface	Run from terminal and output to stdout or JSON
Output mode	Color-coded terminal output + --json export option


‚∏ª

‚úÖ Non-Functional Requirements
	‚Ä¢	Low latency (under 10s per spec)
	‚Ä¢	Works offline with cache or mock LLM
	‚Ä¢	Composability ‚Äî extensible with new checks, possibly as plug-ins

‚∏ª

üß† LangGraph & MCP: Does it Fit?

‚úÖ When LangGraph makes sense:
	‚Ä¢	You want multi-step analysis, with routing logic (e.g. split PR and FAQ and Metrics into separate paths)
	‚Ä¢	You may want modularity: swap in different agents per section
	‚Ä¢	You want state tracking or conversational memory across chunks

Verdict: LangGraph is a good fit if you want composable, section-specific analysis and reusability.

‚∏ª

ü™ú Proposed MVP Plan

‚∏ª

üóÇÔ∏è Phase 1: Skeleton MVP (Tonight)
	‚Ä¢	cli.py script: input .md, output text
	‚Ä¢	Use OpenAI or Groq LLM for a single-shot prompt:
‚ÄúAct as a Staff PM reviewing this PR-FAQ‚Ä¶‚Äù
	‚Ä¢	Parse sections with simple regex
	‚Ä¢	Return structured summary + flags + suggestions

‚∏ª

üèóÔ∏è Phase 2: LangGraph Modular Pass
	‚Ä¢	Break into nodes:
	‚Ä¢	parse_sections
	‚Ä¢	analyze_press_release
	‚Ä¢	analyze_faq
	‚Ä¢	analyze_success_metrics
	‚Ä¢	merge_results
	‚Ä¢	Add scoring logic or plug-in slots for extra checks (e.g., detect_passive_voice)
	‚Ä¢	Export to JSON for GitHub bot compatibility

‚∏ª

üß∞ Phase 3: CI + Collaboration-Ready
	‚Ä¢	Wrap as GitHub Action
	‚Ä¢	Add inline comment suggestions (via PR)
	‚Ä¢	Slack/Teams integration optional

‚∏ª

üß† Prompt Design (First Draft)

System prompt:

You are a Staff Product Manager reviewing a written product document. Your job is to flag areas that are vague, unclear, or lack measurable success criteria. Provide actionable suggestions and identify language that introduces uncertainty or lack of ownership.

User prompt (template):

Here's a PR-FAQ document. Review each section (Press Release, FAQs, Success Metrics) and return:

1. Summary
2. Flags (with line # if possible)
3. Suggestions
4. Overall readiness score (1‚Äì10)

```markdown
<contents of input.md>
